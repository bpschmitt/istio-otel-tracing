newrelic-infrastructure:
  # newrelic-infrastructure.enabled -- Install the [`newrelic-infrastructure` chart](https://github.com/newrelic/nri-kubernetes/tree/main/charts/newrelic-infrastructure)
  enabled: false

nri-prometheus:
  # nri-prometheus.enabled -- Install the [`nri-prometheus` chart](https://github.com/newrelic/nri-prometheus/tree/main/charts/nri-prometheus)
  enabled: false

nri-metadata-injection:
  # nri-metadata-injection.enabled -- Install the [`nri-metadata-injection` chart](https://github.com/newrelic/k8s-metadata-injection/tree/main/charts/nri-metadata-injection)
  enabled: false

kube-state-metrics:
  # kube-state-metrics.enabled -- Install the [`kube-state-metrics` chart](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-state-metrics) from the stable helm charts repository.
  # This is mandatory if `infrastructure.enabled` is set to `true` and the user does not provide its own instance of KSM version >=1.8 and <=2.0. Note, kube-state-metrics v2+ disables labels/annotations
  # metrics by default. You can enable the target labels/annotations metrics to be monitored by using the metricLabelsAllowlist/metricAnnotationsAllowList options described [here](https://github.com/prometheus-community/helm-charts/blob/159cd8e4fb89b8b107dcc100287504bb91bf30e0/charts/kube-state-metrics/values.yaml#L274) in
  # your Kubernetes clusters.
  enabled: false

nri-kube-events:
  # nri-kube-events.enabled -- Install the [`nri-kube-events` chart](https://github.com/newrelic/nri-kube-events/tree/main/charts/nri-kube-events)
  enabled: false

newrelic-logging:
  # newrelic-logging.enabled -- Install the [`newrelic-logging` chart](https://github.com/newrelic/helm-charts/tree/master/charts/newrelic-logging)
  enabled: false

newrelic-pixie:
  # newrelic-pixie.enabled -- Install the [`newrelic-pixie`](https://github.com/newrelic/helm-charts/tree/master/charts/newrelic-pixie)
  enabled: false

newrelic-eapm-agent:
  # nr-eapm-agent.enabled -- Install the [`nr-eapm-agent`](https://github.com/newrelic/helm-charts/tree/master/charts/nr-ebpf-agent)
  enabled: false

k8s-agents-operator:
  # k8s-agents-operator.enabled -- Install the [`k8s-agents-operator` chart](https://github.com/newrelic/k8s-agents-operator/tree/main/charts/k8s-agents-operator)
  enabled: false

pixie-chart:
  # pixie-chart.enabled -- Install the [`pixie-chart` chart](https://docs.pixielabs.ai/installing-pixie/install-schemes/helm/#3.-deploy)
  enabled: false

newrelic-infra-operator:
  # newrelic-infra-operator.enabled -- Install the [`newrelic-infra-operator` chart](https://github.com/newrelic/newrelic-infra-operator/tree/main/charts/newrelic-infra-operator) (Beta)
  enabled: false

newrelic-prometheus-agent:
  # newrelic-prometheus-agent.enabled -- Install the [`newrelic-prometheus-agent` chart](https://github.com/newrelic/newrelic-prometheus-configurator/tree/main/charts/newrelic-prometheus-agent)
  enabled: true
  config:
    kubernetes:
      # NewRelic provides a list of Dashboards, alerts and entities for several Services. The integrations_filter configuration
      # allows to scrape only the targets having this experience out of the box.
      # If integrations_filter is enabled, then the jobs scrape merely the targets having one of the specified labels matching
      # one of the values of app_values.
      # Under the hood, a relabel_configs with 'action=keep' are generated, consider it in case any custom extra_relabel_config is needed.
      integrations_filter:
        # -- enabling the integration filters, merely the targets having one of the specified labels matching
        #    one of the values of app_values are scraped. Each job configuration can override this default.
        enabled: true
        # -- source_labels used to fetch label values in the relabel config added by the integration filters configuration
        source_labels: ["app.kubernetes.io/name", "app.newrelic.io/name", "k8s-app"]
        # -- app_values used to create the regex used in the relabel config added by the integration filters configuration.
        # Note that a single regex will be created from this list, example: '.*(?i)(app1|app2|app3).*'
        app_values: ["redis", "traefik", "calico", "nginx", "coredns", "kube-dns", "etcd", "cockroachdb", "velero", "harbor", "argocd"]

      # Kubernetes jobs define [kubernetes_sd_configs](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#kubernetes_sd_config)
      # to discover and scrape Kubernetes objects. Besides, a set of relabel_configs are included in order to include some Kubernetes metadata as
      # Labels. For example, address, metrics_path, URL scheme, prometheus_io_parameters, namespace, pod name, service name and labels are taken
      # to set the corresponding labels.
      # Please note, the relabeling allows configuring the pod/endpoints scrape using the following annotations:
      # - `prometheus.io/scheme`: If the metrics endpoint is secured then you will need to set this to `https`
      # - `prometheus.io/path`: If the metrics path is not `/metrics` override this.
      # - `prometheus.io/port`: If the metrics are exposed on a different port to the service for service endpoints or to
      #   the default 9102 for pods.
      # - `prometheus.io/param_<param-name>`: To include additional parameters in the scrape URL.
      jobs:
      # 'default' scrapes all targets having 'prometheus.io/scrape: true'.
      # Out of the box, since kubernetes.integrations_filter.enabled=true then only targets selected by the integration filters are considered.
      # - job_name_prefix: default
      #   target_discovery:
      #     pod: true
      #     endpoints: true
      #     filter:
      #       annotations:
      #         prometheus.io/scrape: true
      
      - job_name_prefix: istio
        integrations_filter:
          enabled: false
        target_discovery:
          pod: true
          endpoints: false
          filter:
            annotations:
              prometheus.io/scrape: true
        extra_metric_relabel_config:
          - action: keep
            source_labels: [__name__]
            regex: "istio_(request|response|tcp).*"

newrelic-k8s-metrics-adapter:
  # newrelic-k8s-metrics-adapter.enabled -- Install the [`newrelic-k8s-metrics-adapter.` chart](https://github.com/newrelic/newrelic-k8s-metrics-adapter/tree/main/charts/newrelic-k8s-metrics-adapter) (Beta)
  enabled: false


# -- change the behaviour globally to all the supported helm charts.
# See [user's guide of the common library](https://github.com/newrelic/helm-charts/blob/master/library/common-library/README.md) for further information.
# @default -- See [`values.yaml`](values.yaml)
global:
  # -- The cluster name for the Kubernetes cluster.
  cluster: "istio-tracing"

  # -- The license key for your New Relic Account. This will be preferred configuration option if both `licenseKey` and `customSecret` are specified.
  licenseKey: ""
  # -- The license key for your New Relic Account. This will be preferred configuration option if both `insightsKey` and `customSecret` are specified.
  insightsKey: ""
  # -- Name of the Secret object where the license key is stored
  customSecretName: "newrelic-license-key"
  # -- Key in the Secret object where the license key is stored
  customSecretLicenseKey: "license-key"

  # -- Additional labels for chart objects
  labels: {}
  # -- Additional labels for chart pods
  podLabels: {}

  images:
    # -- Changes the registry where to get the images. Useful when there is an internal image cache/proxy
    registry: ""
    # -- Set secrets to be able to fetch images
    pullSecrets: []

  serviceAccount:
    # -- Add these annotations to the service account we create
    annotations: {}
    # -- Configures if the service account should be created or not
    create:
    # -- Change the name of the service account. This is honored if you disable on this chart the creation of the service account so you can use your own
    name:

  # -- (bool) Sets pod's hostNetwork
  # @default -- false
  hostNetwork:
  # -- Sets pod's dnsConfig
  dnsConfig: {}

  # -- Sets pod's priorityClassName
  priorityClassName: ""
  # -- Sets security context (at pod level)
  podSecurityContext: {}
  # -- Sets security context (at container level)
  containerSecurityContext: {}

  # -- Sets pod/node affinities
  affinity: {}
  # -- Sets pod's node selector
  nodeSelector: {}
  # -- Sets pod's tolerations to node taints
  tolerations: []

  # -- Adds extra attributes to the cluster and all the metrics emitted to the backend
  customAttributes: {}

  # -- (bool) Reduces number of metrics sent in order to reduce costs
  # @default -- false
  lowDataMode:

  # -- (bool) In each integration it has different behavior. See [Further information](#values-managed-globally-3) but all aims to send less metrics to the backend to try to save costs |
  # @default -- false
  privileged:

  # -- (bool) Must be set to `true` when deploying in an EKS Fargate environment
  # @default -- false
  fargate:

  # -- Configures the integration to send all HTTP/HTTPS request through the proxy in that URL. The URL should have a standard format like `https://user:password@hostname:port`
  proxy: ""

  # -- (bool) Send the metrics to the staging backend. Requires a valid staging license key
  # @default -- false
  nrStaging:
  fedramp:
    # fedramp.enabled -- (bool) Enables FedRAMP
    # @default -- false
    enabled:

  # -- (bool) Sets the debug logs to this integration or all integrations if it is set globally
  # @default -- false
  verboseLog:


# To add values to the subcharts. Follow Helm's guide: https://helm.sh/docs/chart_template_guide/subcharts_and_globals

# If you wish to monitor services running on Kubernetes you can provide integrations
# configuration under `integrations_config` that it will passed down to the `newrelic-infrastructure` chart.
#
# You just need to create a new entry where the "name" is the filename of the configuration file and the data is the content of
# the integration configuration. The name must end in ".yaml" as this will be the
# filename generated and the Infrastructure agent only looks for YAML files.
#
# The data part is the actual integration configuration as described in the spec here:
# https://docs.newrelic.com/docs/integrations/integrations-sdk/file-specifications/integration-configuration-file-specifications-agent-v180
#
# In the following example you can see how to monitor a Redis integration with autodiscovery
#
#
# newrelic-infrastructure:
#   integrations:
#     nri-redis-sampleapp:
#       discovery:
#         command:
#           exec: /var/db/newrelic-infra/nri-discovery-kubernetes --tls --port 10250
#           match:
#             label.app: sampleapp
#       integrations:
#         - name: nri-redis
#           env:
#             # using the discovered IP as the hostname address
#             HOSTNAME: ${discovery.ip}
#             PORT: 6379
#           labels:
#             env: test